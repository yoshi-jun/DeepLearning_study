{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed39cb0-130b-4310-81a4-ea493ac55bfc",
   "metadata": {},
   "source": [
    "# 変分オートエンコーダ(VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03309f99-4878-440b-8c6d-a13a46e73a3f",
   "metadata": {},
   "source": [
    "ニューラルネットワークと生成モデルを組み合わせることで、より複雑な表現が可能になっている。\n",
    "\n",
    "ここでは、一例としてVAEについて導出を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61696871-da94-41fc-8d14-53293d2eb4c3",
   "metadata": {},
   "source": [
    "## 7.1 VAEとデコーダ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bb2f98-0238-4bb2-89d2-5abcb453a37c",
   "metadata": {},
   "source": [
    "本書では、始めに一つの正規分布でモデルを作成した。次に複数の正規分布を使用した混合ガウスモデル（GMM)についてモデルを作成した。\n",
    "\n",
    "VAEで目指すのは、学習データに合わせて柔軟に形が決まる確率分布である。変分オートエンコーダーはニューラルネットワークを使用することで、より複雑な表現が可能となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76542c7e-cfad-450a-a4d8-774efdf4029e",
   "metadata": {},
   "source": [
    "### 7.1.1 一つの正規分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953c21f-bb28-4122-9efa-1f39a46e18b0",
   "metadata": {},
   "source": [
    "正規分布のパラメータを$\\theta = \\{ \\mu,\\Sigma\\}$で表す。データ$x$の分布を一つの正規分布でモデル化する場合、確率分布は\n",
    "\n",
    "$$ p_\\theta(x) = \\mathcal{N}(x;\\theta) $$\n",
    "\n",
    "と表される。パラメータ$\\theta$は$N$個の観測データ$\\mathcal{D} = \\{x^{(1)},x^{(2)},\\cdots,x^{(N)}\\}$から、対数尤度が最大になるパラメータを求める。対数尤度は次の式で表される。\n",
    "\n",
    "$$\\log p_\\theta(\\mathcal{D}) = \\log \\left( p_\\theta(x^{(1)})p_\\theta(x^{(2)})\\cdots p_\\theta(x^{(N)})\\right)$$\n",
    "\n",
    "対数尤度を最大にする$\\theta$は$\\frac{\\partial}{\\partial\\theta}\\log p_\\theta(\\mathcal{D})=0$を解くことで求められる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db3467-9d1e-4943-a620-8b25144598dd",
   "metadata": {},
   "source": [
    "### 7.1.2 混合ガウスモデル（GMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b41de6-00fb-4314-afca-1344fc384a22",
   "metadata": {},
   "source": [
    "複数の正規分布から構成されたモデルで、次の二つの作業でデータを生成する。\n",
    "\n",
    "1. $K$個の正規分布の中から、カテゴリカル分布に従って一つを選ぶ\n",
    "2. 選んだ正規分布からデータを生成する\n",
    "\n",
    "GMMでは解析的にパラメータを推定することができない。そこで、ELBOを目的関数とする。\n",
    "\n",
    "$$\\log p_\\theta(\\mathcal{D})\\geq \\sum^N_{n=1}\\sum_{z^{n}}q^{(n)}(z^{(n)})\\log\\frac{p_\\theta(x^{(n)},z^{(n)})}{q^{(n)}(z^{(n)})}$$\n",
    "\n",
    "EMアルゴリズムでは、ELBOを目的関数として以下の作業を繰り返す。\n",
    "\n",
    "1. **Eステップ** : $\\{q^{(1)},q^{(2)},\\cdots,q^{(N)}\\}$の更新\n",
    "\n",
    "各$n$に対して$q^{(n)}(z)=p_\\theta(z|\\boldsymbol{x}^{(n)})$とする\n",
    "\n",
    "2. **Mステップ** : $\\theta$の更新\n",
    "\n",
    "ELBOが最大になる$\\theta$を解析的に求める"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3565016-afba-4b47-aacc-befc02897d6c",
   "metadata": {},
   "source": [
    "### 7.1.3 VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b50e59-181b-4d13-bb94-bcc7953e9b41",
   "metadata": {},
   "source": [
    "ここまで、今までの内容について復習した。ここから、VAEについて考える。\n",
    "\n",
    "VAEはGMMと同様に潜在変数を持つモデルである。\n",
    "\n",
    "1. 潜在変数$z$を固定の正規分布から生成する\n",
    "2. ニューラルネットワークによって潜在変数$z$から観測変数$x$へと変換する\n",
    "\n",
    "VAEではニューラルネットワークを使って、潜在変数$z$から観測変数$x$へと変換を行っている。\n",
    "\n",
    "潜在変数$z$は$H$次元のベクトルとし、次のように表される\n",
    "\n",
    "$$ z = \\begin{pmatrix} z_1 \\\\ z_2 \\\\ \\vdots \\\\ z_H\\end{pmatrix}$$\n",
    "\n",
    "VAEでは、潜在変数は「固定の正規分布」($\\mu = 0, \\Sigma = \\boldsymbol{I}$)から生成されると仮定すると、$z$は$\\mathcal{N}(z;\\boldsymbol{0},\\boldsymbol{I})$に従う。数式で表すと\n",
    "\n",
    "$$p(z) = \\mathcal{N}(z;\\boldsymbol{0},\\boldsymbol{I})$$\n",
    "\n",
    "潜在変数の$z$は$\\mathcal{N}(z;\\boldsymbol{0}, \\boldsymbol{I})$という単純な確率分布から生成されるが、ニューラルネットワークによって複雑な変換を実現することでができる。\n",
    "\n",
    "潜在変数$z$から観測変数$x$への変換を**デコーダー**（**Dercoder**）と呼ばれる。\n",
    "\n",
    "GMMでは、離散的な値$z$をサンプリングする。GMMは潜在変数が一つの離散値に限定される（一つの正規分布から生成するため）。\n",
    "一方VAEでは正規分布から連続な値を持つベクトル$z$をサンプリングするため、多様かつ広範囲な表現が可能である。\n",
    "\n",
    "私たちの目標は、観測変数$x$の確率分布$p(x)$を得ることである。\n",
    "\n",
    "ニューラルネットワークの出力を平均ベクトルとする正規分布を考える。数式で表すと\n",
    "\n",
    "$$ \\hat{x} = \\rm{NeuralNet}(z;\\theta) $$\n",
    "と表される。$z$は入力、$\\hat{x}$は出力、$\\theta$はニューラルネットワークのパラメータを表す。出力される$z$はニューラルネットワークで求めた$\\hat{x}$を用いて\n",
    "\n",
    "$$p_\\theta(x|z) = \\mathcal{N}(x;\\hat{x},\\boldsymbol{I})$$\n",
    "\n",
    "と表される。$x$は$\\hat{x}$を平均ベクトルとする正規分布に従うと考える。ここでは、簡単のため共分散行列を単位行列$I$と仮定する。\n",
    "\n",
    "\n",
    "**ここで、一度まとめ**\n",
    "\n",
    "潜在変数$z$は要素数$K$個のベクトルであり、固定の正規分布に従い生成される。\n",
    "\n",
    "$$p(\\boldsymbol{z}) = \\mathcal{N}(\\boldsymbol{z};\\boldsymbol{0},\\boldsymbol{I})$$\n",
    "\n",
    "次にニューラルネットワークでは、$z$を入力として$\\hat{x}$を生成する。\n",
    "\n",
    "$$\\hat{x} = \\rm{Neuralnet}(\\boldsymbol{z};\\boldsymbol{\\theta})$$\n",
    "\n",
    "最後に、VAEの出力$x$は\n",
    "\n",
    "$$p(\\boldsymbol{x}|\\boldsymbol{z}) = \\mathcal{N}(\\boldsymbol{x};\\hat{\\boldsymbol{x}},\\boldsymbol{I})$$\n",
    "\n",
    "と表される。$x$は$\\hat{x}$を平均ベクトルとする正規分布に従い（$\\boldsymbol{\\mu} = \\boldsymbol{\\hat{x}}$の正規分布に従う）サンプリングされる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d6149-1dee-429d-9a1d-c1340b196de4",
   "metadata": {},
   "source": [
    "### 7.1.4 EMアルゴリズムの問題点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796c996-46ad-4e0d-b311-a35bf8a2f423",
   "metadata": {},
   "source": [
    "Eステップでは、$q^{(n)}(\\boldsymbol{z}) = p_\\theta(\\boldsymbol{z}|\\boldsymbol{x}^{(n)})$という計算を行う。\n",
    "\n",
    "潜在変数を持つモデルの対数尤度は、潜在変数$z$を生成する任意の確率分布$q(z)$を使用して\n",
    "\n",
    "$$\\log p_\\theta(x) = \\sum q(z) \\log\\frac{p_\\theta(x,z)}{q(z)}+D_{KL}(q(z)||p_\\theta(z|x))$$\n",
    "\n",
    "と表される。第二項を最小化するステップがEステップである。これは、KLダイバージェンスを0に近づけるための操作である。\n",
    "\n",
    "VAEの場合、\n",
    "\n",
    "$$p_\\theta(\\boldsymbol{z}|\\boldsymbol{x}^{(n)}) = \\frac{p_\\theta(\\boldsymbol{x}^{(n)} | \\boldsymbol{z})}{p_\\theta(\\boldsymbol{x}^{(n)})}\\\\\n",
    " = \\frac{p_\\theta(\\boldsymbol{x}^{(n)} | \\boldsymbol{z})}{\\int p_\\theta(\\boldsymbol{x}^{(n)} | \\boldsymbol{z})dz}$$\n",
    " \n",
    "の計算を行う必要がある。GMMの場合はカテゴリカル分布であったため積分を行うことができた。一方VAEでは潜在変数は次元数$K$の多次元ベクトルであり、すべてのとり得る値について積分を行うことは不可能である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025a34e9-9a42-4814-865c-2e197cc48c4f",
   "metadata": {},
   "source": [
    "## 7.2 VAEとエンコーダー"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007ee89-0693-4fb2-8f48-71648fb3e8a5",
   "metadata": {},
   "source": [
    "EMアルゴリズムを改良することで、VAEの学習が行えるようになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df07fa34-65d2-4355-9671-b63bd24e533d",
   "metadata": {},
   "source": [
    "### 7.2.1 EMアルゴリズムからVAEへ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702ceda-cebd-4093-97e1-8eefa70a6b8b",
   "metadata": {},
   "source": [
    "対数尤度から、任意の確率分布$q(\\boldsymbol{z})$を用いて次のように式を展開した。\n",
    "\n",
    "$$\\log p_\\theta(x) = \\log p_\\theta(x) \\int q(z) dz \\\\\n",
    " = \\left(\\int q(z)dz\\right)\\log{p_\\theta(x)}dz\\\\\n",
    " = \\int q(z) \\log\\frac{p_\\theta(x,z)}{p_\\theta(z|x)}dz\\\\\n",
    " = \\int q(z) \\log\\frac{p_\\theta(x,z)}{q(z)}dz+\\int q(z)\\log\\frac{q(z)}{p_\\theta(z|x)}dz$$\n",
    "\n",
    "対数尤度は、二つの項の和として表される。（連続変数であるため、$\\sum$から$\\int$に変化していることに注意）\n",
    "\n",
    "KLダイバージェンスの最小値は$0$であるため、次の式が成立する。\n",
    "\n",
    "$$\\log p_\\theta(x) = \\int q(z) \\log\\frac{p_\\theta(x,z)}{q(z)}dz+D_{KL}(q(z)||p_\\theta(z|x))\\\\\n",
    "\\geq \\int q(z) \\log\\frac{p_\\theta(x,z)}{q(z)}$$\n",
    " \n",
    "よって\n",
    "\n",
    "$$\\rm{ELBO}(x;q,\\theta)=\\sum_zq(z)\\log\\frac{p_\\theta(x,z)}{q(z)}$$\n",
    "\n",
    "と表せる。この式から、$\\rm{ELBO}(x;q,\\theta)$を大きくすることで、対数尤度を大きくすることがわかる。\n",
    "\n",
    "EMアルゴリズムでは、$q(\\boldsymbol{z}),\\boldsymbol{\\theta}$を交互に更新する。VAEでは事後分布$q^{(n)}(\\boldsymbol{z}) = p_\\theta(\\boldsymbol{z}|\\boldsymbol{x}^{(n)})$を直接求めることが困難です。そこで、以下のアプローチを取る。\n",
    "\n",
    "1. $q(z)$を簡単な確率分布(例:正規分布)に限定する\n",
    "2. 限定された確率分布の中でELBOの最大化を行う\n",
    "\n",
    "VAEの潜在変数は十数のベクトルである。そこで、確率分布$q(\\boldsymbol{z})$を正規分布に限定する。正規分布のパラメータを$\\psi = \\{\\boldsymbol{\\mu},\\boldsymbol{\\Sigma}\\}$として$q(\\boldsymbol{z})$を次のように記述する。\n",
    "\n",
    "$$q_\\psi(z) = \\mathcal{N}(\\boldsymbol{z};\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$$\n",
    "\n",
    "これにより、対数尤度は\n",
    "\n",
    "$$\\log p_\\theta(x) = \\int q_\\psi(z) \\log\\frac{p_\\theta(x,z)}{q_\\psi(z)}dz+D_{KL}(q_\\psi(z)||p_\\theta(z|x))$$\n",
    "\n",
    "よって、私たちの目標は次のELBOを$\\boldsymbol{\\theta},\\boldsymbol{\\psi}$に関して最大化することです。\n",
    "\n",
    "$$\\rm{ELBO}(x;\\theta,\\psi) = \\int q_\\psi(z) \\log\\frac{p_\\theta(x,z)}{q_\\psi(z)}dz$$\n",
    "\n",
    "ELBOを$\\psi$に関して最大化すると、$q_\\psi(\\boldsymbol{z}$は$p_\\theta(\\boldsymbol{z}|\\boldsymbol{x})$に最も近づく。\n",
    "\n",
    "$\\psi$を変化させた場合でも、対数尤度の値は変化しない。つまり、ELBOとKLダイバージェンスの割合が変化している。\n",
    "\n",
    "$\\psi$を最大化させた場合、KLダイバージェンスはゼロになる。つまり、$q_\\psi(\\boldsymbol{z})$が$p_\\theta(\\boldsymbol{z}|\\boldsymbol{x})$に近づく。\n",
    "\n",
    "計算不可能な事後分布$p_\\theta(\\boldsymbol{z}|\\boldsymbol{x})$を正規分布で近似した。このような手法を変分近似(Variational Approximation)や変数ベイズ(Variational Bayes)と呼ばれる。\n",
    "VAEのVはVariationalのVから来ている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73120f9-a6e2-4103-bdd2-d3fe02bdc0c1",
   "metadata": {},
   "source": [
    "### 7.2.2 データセット全体への適用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b5179-8664-437e-8458-ed719d673bd9",
   "metadata": {},
   "source": [
    "先に求めた$\\rm{ELBO}(x;\\theta,\\psi)$は一つのデータに対しての式であった。実際には、$N$個のデータを扱う必要がある。よって次の関数が目的関数となる。\n",
    "\n",
    "$$\\sum^N_{n=1}\\rm{ELBO}(\\boldsymbol{x};\\theta,\\psi)=\\sum^N_{n=1}\\int q_{\\psi^{(n)}}(\\boldsymbol{z}) \\log\\frac{p_\\theta(\\boldsymbol{x}^{(n)},\\boldsymbol{z})}{q_{\\psi^{(n)}}(\\boldsymbol{z})}d\\boldsymbol{z}$$\n",
    "\n",
    "ここでは、各データ$\\boldsymbol{x}^{(n)}$に対応した確率分布$q_{\\psi^{(n)}}(\\boldsymbol{z})$を用意する。ここで、$q_{\\psi^{(n)}}(\\boldsymbol{z})$はパラメータ$\\psi^{(n)}=\\{\\boldsymbol{\\mu}^{(n)},\\boldsymbol{\\Sigma}^{(n)}\\}$の正規分布である。ELBOを最大化することで、$q_{\\psi^{(n)}}(\\boldsymbol{z})$は事後分布$p_\\theta(\\boldsymbol{z}|\\boldsymbol{x}^{(n)})$に近づくようにパラメータが更新される。\n",
    "\n",
    "しかし、大きなデータセットの場合、$N=100,000,000$では用意する確率分布も同じだけ必要になるため、非現実的です。これを解決するために、ニューラルネットワークを使用する。\n",
    "(GMMの場合はカテゴリカル分布で$K$個の正規分布から選択した)\n",
    "\n",
    "各データ$\\boldsymbol{x}^{(n)}$に対応した正規分布のパラメータ$\\psi^{(n)}=\\{\\boldsymbol{\\mu}^{(n)},\\boldsymbol{\\Sigma}^{(n)}\\}$がある。そこで、入力を$\\boldsymbol{x}^{(n)}$、出力を$\\{\\boldsymbol{\\mu}^{(n)},\\boldsymbol{\\Sigma}^{(n)}\\}$とするニューラルネットワークで代用する。そして、このニューラルネットワークのパラメータは$\\phi$で表す。観測データから潜在変数へと変換するので、エンコーダ(Encoder)と呼ばれる。\n",
    "\n",
    "近似後分布のパラメータを一つのニューラルネットワークによって計算する手法は償却推論(Amortized Inference)と呼ばれる。\n",
    "\n",
    "潜在変数$z$が次元数$H$のベクトルとすると、ニューラルネットワークの平均ベクトル$\\mu$も次元数$H$である。また共分散行列$\\Sigma$を対角共分散行列に限定することで、要素数を$H$に削減することができる。\n",
    "\n",
    "よってニューラルネットワークの出力は次の二つのベクトルとなる。\n",
    "\n",
    "$$\\boldsymbol{\\mu} = \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\\\ \\vdots \\\\ \\mu_H \\end{pmatrix}\\\\\n",
    "\\boldsymbol{\\sigma} = \\begin{pmatrix} \\sigma_1 \\\\ \\sigma_2 \\\\ \\vdots \\\\ \\sigma_H \\end{pmatrix}$$\n",
    "\n",
    "\n",
    "以上をまとめると、VAEのエンコーダで行う処理は次の式で表される。\n",
    "\n",
    "$$\\boldsymbol{\\mu},\\boldsymbol{\\sigma} = \\rm{NeuralNet}(\\boldsymbol{x};\\boldsymbol{\\phi})\\\\\n",
    "q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{z};\\boldsymbol{\\mu},\\boldsymbol{\\sigma}^2\\boldsymbol{I})$$\n",
    "\n",
    "ここで、$\\boldsymbol{\\sigma^2I}$は対角成分共分散行列を表す。\n",
    "\n",
    "$$\\boldsymbol{\\sigma^2I} = \\begin{pmatrix} \n",
    "\\sigma^2_1 & 0 & \\cdots & 0 \\\\\n",
    "0 & \\sigma^2_2 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & \\sigma^2_H \n",
    "\\end{pmatrix}$$\n",
    "\n",
    "以上で、VAEを構成する要素がすべて登場しました。次は、VAEのパラメータ推定についてです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a3c9b8-8048-4e1f-b771-dffdab126a6a",
   "metadata": {},
   "source": [
    "## 7.3 ELBOの最適化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397e487-66fe-4874-bdad-5ac5fabb46f6",
   "metadata": {},
   "source": [
    "一度整理をする。VAEの各ネットワークは次の式で表される。\n",
    "\n",
    "**デコーダ**\n",
    "\n",
    "$$p(\\boldsymbol{z}) = \\mathcal{N}(\\boldsymbol{z};\\boldsymbol{0},\\boldsymbol{I})$$\n",
    "$$\\hat{x} = \\rm{Neuralnet}(\\boldsymbol{z};\\boldsymbol{\\theta})$$\n",
    "$$p(\\boldsymbol{x}|\\boldsymbol{z}) = \\mathcal{N}(\\boldsymbol{x};\\hat{\\boldsymbol{x}},\\boldsymbol{I})$$\n",
    "\n",
    "**エンコーダ**\n",
    "$$\\boldsymbol{\\mu},\\boldsymbol{\\sigma} = \\rm{NeuralNet}(\\boldsymbol{x};\\boldsymbol{\\phi})$$\n",
    "$$q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{z};\\boldsymbol{\\mu},\\boldsymbol{\\sigma}^2\\boldsymbol{I})$$\n",
    "\n",
    "二つのニューラルネットワークを使用したモデルにおいて、対数尤度を最大化する$\\boldsymbol{\\theta,\\phi}$を見つけることである。対数尤度そのものを最大化することは難しいため、ELBOを最大化することを考える。\n",
    "\n",
    "$$\\rm{ELBO}(x;\\theta,\\phi) = \\int q_\\phi(z) \\log\\frac{p_\\theta(x,z)}{q_\\phi(z|x)}dz$$\n",
    "\n",
    "実際には$N$個のデータがあるため、目的関数は\n",
    "\n",
    "$$\\sum^N_{n=1}\\rm{ELBO}(\\boldsymbol{x};\\theta,\\phi)=\\sum^N_{n=1}\\int q_{\\phi^{(n)}}(\\boldsymbol{z}) \\log\\frac{p_\\theta(\\boldsymbol{x}^{(n)},\\boldsymbol{z})}{q_{\\phi^{(n)}}(\\boldsymbol{z}|\\boldsymbol{x})}d\\boldsymbol{z}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24821072-02f3-4e8d-9908-63d755a4f540",
   "metadata": {},
   "source": [
    "### 7.3.1 ELBOの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f154d-07ca-4277-9712-fbbca9a9b863",
   "metadata": {},
   "source": [
    "ELBOを最大化するために、ELBOの評価を行う。始めに、一つのデータに対するELBOについて考える。\n",
    "\n",
    "$$\\rm{ELBO}(x;\\theta,\\phi) = \\int q_\\phi(z) \\log\\frac{p_\\theta(x,z)}{q_\\phi(z|x)}dz$$\n",
    "\n",
    "と表された。ここで、$p_\\theta(\\boldsymbol{x},\\boldsymbol{z}) = p_\\theta(\\boldsymbol{x}|\\boldsymbol{z})p(\\boldsymbol{z})$より\n",
    "\n",
    "$$\\rm{ELBO}(x;\\theta,\\phi) =　\\int q_\\phi(z) \\log\\frac{p_\\theta(\\boldsymbol{x}|\\boldsymbol{z})p(\\boldsymbol{z})}{q_\\phi(z|x)}dz\\\\\n",
    " = \\int q_\\phi(z) \\log p_\\theta(\\boldsymbol{x}|\\boldsymbol{z})dz+\\int q_\\phi(z) \\log\\frac{p(\\boldsymbol{z})}{q_\\phi(z|x)}dz\\\\\n",
    " = \\int q_\\phi(z) \\log p_\\theta(\\boldsymbol{x}|\\boldsymbol{z})dz-\\int q_\\phi(z) \\log\\frac{q_\\phi(z|x)}{p(\\boldsymbol{z})}dz\\\\\n",
    " $$\n",
    " \n",
    "と表せる。この展開により、ELBOを二つの項の和として表すことができ、第一項は期待値、第二項はKLダイバージェンスとして表すことができる。\n",
    "\n",
    "$$ \\rm{ELBO}(\\boldsymbol{x;\\theta,\\phi}) = \\mathbb{E}_{q_\\phi(\\boldsymbol{x|z})}[\\log p_\\boldsymbol{\\theta}(\\boldsymbol{x|z})]-\\rm{D}_{\\rm{KL}}(q_\\boldsymbol{\\phi}(\\boldsymbol{x|z})||p(\\boldsymbol{z}))$$\n",
    "\n",
    "ここでは、第一項を$J_1$第二項を$J_2$と定義する。始めに$J_1$の計算からみていく。\n",
    "\n",
    "$J_1$は期待値なので、$q_\\boldsymbol{\\phi}(\\boldsymbol{z|x}$からいくつか乱数を生成し、$\\log p_\\boldsymbol{\\theta}(\\boldsymbol{z|x})$の平均を計算する。サンプルサイズが１の場合、$z\\sim q_\\boldsymbol{\\phi}(\\boldsymbol{z|x}$によって$\\boldsymbol{z}$をサンプリングし$\\log p_\\boldsymbol{\\theta}(\\boldsymbol{x|z}$を計算することで$J_1$を近似することができる。\n",
    "\n",
    "$$\\boldsymbol{\\mu},\\boldsymbol{\\sigma} = \\rm{NeuralNet}(\\boldsymbol{x};\\boldsymbol{\\phi})$$\n",
    "$$\\boldsymbol{z} \\sim \\mathcal{N}(\\boldsymbol{z;\\mu,\\sigma^2I})$$\n",
    "$$\\hat{\\boldsymbol{x}} = \\rm{NeuralNet}(\\boldsymbol{z;\\theta})$$\n",
    "$$J_1 \\approx \\log \\mathcal{N}(\\boldsymbol{x;\\hat{x},I})$$\n",
    "\n",
    "エンコーダが入力データ$\\boldsymbol{x}$から$\\boldsymbol{z}$をサンプリングする。そして、デコーダによってデータ$\\hat{\\boldsymbol{x}}$が再度生成される。\n",
    "\n",
    "この$\\hat{\\boldsymbol{x}}$が入力データ$\\boldsymbol{x}$に近いほど$J_1$は大きくなる。従って、再構成誤差項とも呼ばれる。\n",
    "\n",
    "なお$J_1 \\approx \\log \\mathcal{N}(\\boldsymbol{x;\\hat{x},I})$の計算をさらに進めると\n",
    "\n",
    "$$J_1 \\approx \\log \\mathcal{N}(\\boldsymbol{x;\\hat{x},I})\\\\\n",
    "= \\log\\left(\\frac{1}{\\sqrt{(2\\pi)^D|\\boldsymbol{I}|}} \\exp{\\left(-\\frac{1}{2}(\\boldsymbol{x}-\\hat{\\boldsymbol{x}})^\\top \\boldsymbol{I}^{-1}(\\boldsymbol{x}-\\hat{\\boldsymbol{x}})\\right)}\\right)\\\\\n",
    " = -\\frac{1}{2}(\\boldsymbol{x}-\\hat{\\boldsymbol{x}})^\\top (\\boldsymbol{x}-\\hat{\\boldsymbol{x}})+\\log\\frac{1}{\\sqrt{(2\\pi)^D}}\\\\\n",
    " = -\\frac{1}{2}\\sum^D_{d=1}(x_d -\\hat{x}_d)^2+\\rm{const}\n",
    "$$\n",
    "となる。定数項はパラメータの最適化に寄与しないため、$\\rm{const}$と表記する。また、$(\\boldsymbol{x}-\\hat{\\boldsymbol{x}})^\\top (\\boldsymbol{x}-\\hat{\\boldsymbol{x}})$はベクトルの内積を表し、二乗誤差として表すことができる。($D$は次元数)\n",
    "\n",
    "\n",
    "次に、第二項のKLダイバージェンスについて考える。KLダイバージェンス項が$0$に近づくほど、ELBOは大きくなる。よって、$p_\\phi(\\boldsymbol{x|z}) = p(\\boldsymbol{z})$となることか望ましい。この項は二つの確率分布の整合性を判定することから、整合性項と呼ばれる。\n",
    "\n",
    "$\\rm{D}_{\\rm{KL}}(q_\\boldsymbol{\\phi}(\\boldsymbol{x|z})||p(\\boldsymbol{z}))$の実際の計算をみる。\n",
    "\n",
    "二つの確率分布は正規分布で表すことができ、\n",
    "\n",
    "$$ q_\\boldsymbol{\\phi}(\\boldsymbol{x|z}) = \\mathcal{N}(\\boldsymbol{z};\\boldsymbol{\\mu},\\boldsymbol{\\sigma^2I})\\\\\n",
    "p(\\boldsymbol{z}) = \\mathcal{N}(\\boldsymbol{z};\\boldsymbol{0},\\boldsymbol{I})$$\n",
    "\n",
    "で表される。\n",
    "\n",
    "二つの正規分を仮に$q(\\boldsymbol{z}) = \\mathcal{N}(\\boldsymbol{z};\\boldsymbol{\\mu}_1,\\boldsymbol{\\sigma}^2_1\\boldsymbol{I}),p(\\boldsymbol{x}|\\boldsymbol{z}) = \\mathcal{N}(\\boldsymbol{z};\\boldsymbol{\\mu}_2,\\boldsymbol{\\sigma}^2_2\\boldsymbol{I})$とするとKLダイバージェンスは\n",
    "\n",
    "$$\\rm{D}_{rm{KL}}(q||p) = \\frac{1}{2}\\sum^H_{h=1}\\left(1+\\log\\frac{\\sigma^2_{1,h}}{\\sigma^2_{2,h}}-\\frac{(\\mu_{1,h}-\\mu_{2,h})^2}{\\sigma^2_{2,h}}-\\frac{\\sigma^2_{1,h}}{\\sigma^2_{2,h}}\\right)$$\n",
    "\n",
    "で計算することができる。\n",
    "\n",
    "これにより、\n",
    "\n",
    "$$J_2 = \\rm{D}_{\\rm{KL}}(q_\\boldsymbol{\\phi}(\\boldsymbol{x|z})||p(\\boldsymbol{z}))\\\\\n",
    " = -\\frac{1}{2}\\sum^H_{h=1}(1+\\log{\\sigma^2_h} -\\mu^2_h -\\sigma^2_h)$$\n",
    " \n",
    "となる。\n",
    "\n",
    "以上より、ELBOの各項の計算は\n",
    "\n",
    "$$\\rm{ELBO}(\\boldsymbol{x};\\boldsymbol{\\theta},\\boldsymbol{\\phi})= J_1 - J_2 \\\\\n",
    " = - \\frac{1}{2}\\sum^D_{d=1}(x_d -\\hat{x}_d)^2+\\frac{1}{2}\\sum^H_{h=1}(1+\\log{\\sigma^2_h} -\\mu^2_h -\\sigma^2_h)+\\rm{const}$$\n",
    " \n",
    "と表される。エンコーダとデコーダを持つモデルはオートエンコーダを連想させることから変分オートエンコーダ（VAE）と呼ばれる。\n",
    "\n",
    "あとは、このELBOを最大化するために$\\boldsymbol{\\theta},\\boldsymbol{\\phi}$を最大化させる。これら二つのパラメータは勾配法によって更新することができる。\n",
    "しかし、サンプリングを行っている部分ではバックプロぱゲーションが使用できない。そこで、変数変換トリックを使用する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e023a-2d82-4531-b2ba-1b711f16298e",
   "metadata": {},
   "source": [
    "### 7.3.2 変数変換トリック"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d1e0e6-1691-45e1-921a-3978786f37a6",
   "metadata": {},
   "source": [
    "変数変換トリックでは$z\\sim\\mathcal{N}(\\boldsymbol{z};\\boldsymbol{\\mu},\\boldsymbol{\\sigma}^2\\boldsymbol{I})$のサンプリングを次のように計算する。\n",
    "\n",
    "$$\\epsilon\\sim\\mathcal{N}(\\epsilon;,\\boldsymbol{0},\\boldsymbol{I})\\\\\n",
    "z = \\boldsymbol{\\mu} + \\boldsymbol{\\sigma}\\odot \\epsilon\n",
    "$$\n",
    "\n",
    "サンプリングした$\\epsilon$を用いて$\\boldsymbol{\\mu} + \\boldsymbol{\\sigma}\\odot \\epsilon$の変換を行う。実際にベクトルの要素を表すと\n",
    "\n",
    "$$z = \\boldsymbol{\\mu} + \\boldsymbol{\\sigma}\\odot \\epsilon\\\\\n",
    "= \\begin{pmatrix}\\mu_1\\\\\\mu_2\\\\\\vdots\\mu_H\\end{pmatrix}+\\begin{pmatrix}\\sigma_1\\\\\\sigma_2\\\\\\vdots\\sigma_H\\end{pmatrix}\\odot\\begin{pmatrix}\\epsilon_1\\\\\\epsilon_2\\\\\\vdots\\epsilon_H\\end{pmatrix}\\\\\n",
    "= \\begin{pmatrix}\\mu_1+\\sigma_1\\epsilon_1\\\\\\mu_2+\\sigma_2\\epsilon_2\\\\\\vdots\\\\\\mu_H+\\sigma_H\\epsilon_H\\end{pmatrix}\n",
    "$$\n",
    "これにより、平均と分散($\\boldsymbol{\\mu},\\boldsymbol{\\sigma}$)の購買の伝搬が途切れることなく進む。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f7d3d4-a13e-4a94-979c-aafd8c5cc213",
   "metadata": {},
   "source": [
    "## 7.4 VAEの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9fc095-1cff-4835-ab29-6340b2fa3f60",
   "metadata": {},
   "source": [
    "VAEでは、高次元で複雑なデータの分布を学習することができる。そこで、手書き数字の画像データセットMNISTを学習し生成することとする。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6792a3-d7fb-4c1a-ae46-5b6e1ba460a7",
   "metadata": {},
   "source": [
    "### 7.4.1 実装の方針"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d357d-c872-4aa4-bbc2-8bf4f57a35b2",
   "metadata": {},
   "source": [
    "VAEのELBOは\n",
    "$$\\rm{ELBO}(\\boldsymbol{x};\\boldsymbol{\\theta},\\boldsymbol{\\phi})= -\\frac{1}{2}\\sum^D_{d=1}(x_d -\\hat{x}_d)^2+\\frac{1}{2}\\sum^H_{h=1}(1+\\log{\\sigma^2_h} -\\mu^2_h -\\sigma^2_h)+\\rm{const}$$\n",
    "と表すことができた。ニューラルネットワークの学習では損失関数として最小化する関数を設定することが一般的であるため、ELBOにマイナスをかけた次の関数を損失関数とする。\n",
    "\n",
    "$$\\rm{Loss}(\\boldsymbol{x};\\boldsymbol{\\theta},\\boldsymbol{\\phi})= \\sum^D_{d=1}(x_d -\\hat{x}_d)^2-\\sum^H_{h=1}(1+\\log{\\sigma^2_h} -\\mu^2_h -\\sigma^2_h)$$\n",
    "\n",
    "ELBOを二倍しているが、学習率の変更で同じ問題設定になるため問題はない。また、定数項はパラメータを最適化する上では影響がないため省略できる。\n",
    "\n",
    "図7-12で示された計算グラフをPyTorchで実装する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a568d09-a3db-4ec8-8eae-ba13af08928c",
   "metadata": {},
   "source": [
    "### 7.4.2 VAEのコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436654bd-cfff-42fb-8aa0-ac46a28ff730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "input_dim = 784  # x dimension\n",
    "hidden_dim = 200  # neurons in hidden layers\n",
    "latent_dim = 20  # z dimension\n",
    "epochs = 30\n",
    "learning_rate = 3e-4\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):                                      # 2層のニューラルネットワークとして実装\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, hidden_dim)         # 一層目\n",
    "        self.linear_mu = nn.Linear(hidden_dim, latent_dim)     # muを出力するレイヤー（二層目の一つ目）\n",
    "        self.linear_logvar = nn.Linear(hidden_dim, latent_dim) # log sigma^2を出力するレイヤー（二層目の二つ目）\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear(x)                                     # 入力から一回目の線形変換\n",
    "        h = F.relu(h)                                          # 活性化関数ReLUを使用\n",
    "        mu = self.linear_mu(h)                                 # 平均を出力する\n",
    "        logvar = self.linear_logvar(h)                         # log sigma^2を出力\n",
    "        sigma = torch.exp(0.5 * logvar)                        # sigmaを計算\n",
    "        return mu, sigma\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):    # エンコーダー同様に二層のニューラルネットワークとして実装\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(latent_dim, hidden_dim)       # 一層目\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)       # 二層目\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.linear1(z)                                    # 入力から一回目の線形変換\n",
    "        h = F.relu(h)                                          # 活性化関数ReLUによる非線形変換\n",
    "        h = self.linear2(h)                                    # 二回目の線形変換\n",
    "        x_hat = F.sigmoid(h)                                   # スケールを[0:1]に合わせるためシグモイド関数を使用し正規化\n",
    "        return x_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e7b9f-a433-42c9-bd81-d9248286ea11",
   "metadata": {},
   "source": [
    "カーネルが死ぬため実行できない。おそらく、メモリ不足が原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfdd2c8-6747-48fe-838b-29e6b2225626",
   "metadata": {},
   "source": [
    "次にVAEクラスを実装する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2088b285-6dad-4db2-b9f8-7e57b909a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu, sigma):                                           # 変数変換トリック関数\n",
    "    eps = torch.randn_like(sigma)                                        # epsilonをsigmaと同じ形状で正規分布からサンプリング\n",
    "    z = mu + eps * sigma                                                 # z を計算\n",
    "    return z\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)         # エンコーダを定義\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)         # デコーダを定義\n",
    "\n",
    "    def get_loss(self, x):                                                # 損失関数(ELBOにほぼマイナスをかけたもの)を計算\n",
    "        mu, sigma = self.encoder(x)                                       # 平均と分散をそれぞれエンコーダから取得\n",
    "        z = reparameterize(mu, sigma)                                     # 変数変換を行いzを計算\n",
    "        x_hat = self.decoder(z)\n",
    "\n",
    "        batch_size = len(x)                                               # バッチサイズを計算\n",
    "        L1 = F.mse_loss(x_hat, x, reduction='sum')                        # xとhat{x}の二乗平均を計算\n",
    "        L2 = - torch.sum(1 + torch.log(sigma ** 2) - mu ** 2 - sigma ** 2)# 正規分布のKLダイバージェンスの計算\n",
    "        return (L1 + L2) / batch_size                                     # 平均を計算してlossとして出力\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d81564-2177-4dc3-ad04-5d7fce405e10",
   "metadata": {},
   "source": [
    "### 7.4.3 学習を行うコード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ab16f-000c-43e6-9972-204adb8c5f4b",
   "metadata": {},
   "source": [
    "データの読み込みと学習を行うコードを示す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab296b55-b1ed-49fe-846d-5a27e2218bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:16<00:00, 613933.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 150692.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:03<00:00, 440909.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 2317300.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "46.87550068639119\n",
      "42.12246333516439\n",
      "40.90496704508463\n",
      "40.38280959828695\n",
      "40.01107913360596\n",
      "39.81362055714925\n"
     ]
    }
   ],
   "source": [
    "# datasets\n",
    "transform = transforms.Compose([                                                       # 入力データの変換を定義\n",
    "                transforms.ToTensor(),                                                 # 行列に変換\n",
    "                transforms.Lambda(torch.flatten)                                       # falattenを使用して1行に変換         \n",
    "            ])\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)# ./dataにデータを保存しつつ格納\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True) # batch_sizeにデータを分割しシャッフルした状態で格納\n",
    "\n",
    "model = VAE(input_dim, hidden_dim, latent_dim)                                         # VAEクラスのインスタンスを作成\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)                           # オプティマイザをAdamで定義\n",
    "losses = []                                                                            # 損失関数を記録するための配列を用意\n",
    "\n",
    "for epoch in range(epochs):                                                            # epochsだけ学習を繰り返す\n",
    "    loss_sum = 0.0                                                                     # 損失を初期化\n",
    "    cnt = 0                                                                            # カウンターを初期化\n",
    "\n",
    "    for x, label in dataloader:                                                        # データローダからデータ（x）と正解ラベル(label)をbatch_size個取得\n",
    "        optimizer.zero_grad()                                                          # オプティマイザの初期化\n",
    "        loss = model.get_loss(x)                                                       # 損失を計算\n",
    "        loss.backward()                                                                # 微分\n",
    "        optimizer.step()                                                               # パラメータを更新\n",
    "\n",
    "        loss_sum += loss.item()                                                        # 損失をloss_sumに加算\n",
    "        cnt += 1                                                                       # カウントを+1\n",
    "\n",
    "    loss_avg = loss_sum / cnt                                                          # 損失の平均を計算\n",
    "    print(loss_avg)\n",
    "    losses.append(loss_avg)                                                            # 損失の平均を記録"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6098584f-872e-45e2-856c-2ec8d5b87c52",
   "metadata": {},
   "source": [
    "記録した損失関数をプロットすると"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5602be-356c-4f67-acaf-30cce1176286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "epochs = list(range(1, epochs + 1))\n",
    "plt.plot(epochs, losses, marker='o', linestyle='-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f943a-4b1b-4019-bc10-4fbdb7519a4b",
   "metadata": {},
   "source": [
    "### 7.4.4 新しい画像の生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c134bb07-aae6-4239-9dc0-e47d003b481c",
   "metadata": {},
   "source": [
    "VAEの学習が完了すると、新しい画像を生成することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46641bce-3f29-4e5d-a36c-1c6203c14dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new images\n",
    "with torch.no_grad():                                                                      # 勾配計算を無効化\n",
    "    sample_size = 64                                                                       # サンプルサイズを定義\n",
    "    z = torch.randn(sample_size, latent_dim)                                               # サンプルサイズ分(64個）の潜在変数をlatent_dimに従って生成\n",
    "    x = model.decoder(z)                                                                   # モデルのデコーダに潜在変数を入力\n",
    "    generated_images = x.view(sample_size, 1, 28, 28)                                      # 形状を画像の形状に変換\n",
    "\n",
    "grid_img = torchvision.utils.make_grid(generated_images, nrow=8, padding=2, normalize=True)# 生成された画像をグリッド状に並べる。\n",
    "plt.imshow(grid_img.permute(1, 2, 0))                                                      # 画像の出力\n",
    "plt.axis('off')                                                                            # 軸の非表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ecfc8-5652-4fc8-a2ad-874a7d64926f",
   "metadata": {},
   "source": [
    "手書きの数字の大まかな特徴を捉えていることがわかるらしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c5c4f-4881-450c-9a0b-9a26d3e65125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
