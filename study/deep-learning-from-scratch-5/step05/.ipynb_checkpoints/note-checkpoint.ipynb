{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fa7b5f-c5d9-495f-9240-aa4c750e246f",
   "metadata": {},
   "source": [
    "# 5 EMアルゴリズム"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76edc8e7-a070-4d97-831b-c061d37faebb",
   "metadata": {},
   "source": [
    "EMアルゴリズムを使用することで、混合ガウスモデル（GMM）のパラメータ推定を効率的に行うことができる。\n",
    "\n",
    "今回のステップでは、EMアルゴリズムの導出と、実装を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fddeb3d-eb16-46aa-9989-668087163ba6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.1 KLダイバージェンス"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09928fdf-9349-4475-9f67-16761b616a53",
   "metadata": {},
   "source": [
    "EMアルゴリズムの導出に重要な役割を果たす、KLダイバージェンスについて学ぶ。\n",
    "\n",
    "また、数式の表記方法に二つの変更点を加える。まずは、変更点から話す。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d89c5-f481-4368-ae51-f8d02188cec4",
   "metadata": {},
   "source": [
    "### 5.1.1 数式の表記について"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1010c-e9d3-497b-8aa6-ab0f5d744e6d",
   "metadata": {},
   "source": [
    "一つ目の変更点は、期待値の表記方法についてである。連続の確率変数$x$と、確率密度が$p(x)$で表されるとき、$f(x)$の期待値は次の式で表される。\n",
    "\n",
    "$$\\mathbb{E}_{p(x)}[f(x)] = \\int f(x)p(x)dx$$\n",
    "\n",
    "これまで、期待値は$\\mathbb{E}[f(x)]$と表記したが、$p(x)$に関する期待値であることを明示する。例えば、確率分布$q(x)$に関する期待値であれば、\n",
    "\n",
    "$$\\mathbb{E}_{q(x)}[f(x)]=\\int f(x)q(x)dx$$\n",
    "\n",
    "と表される。\n",
    "\n",
    "二つ目の変更点は、パラメータの表記場所である。パラメータ$\\theta$の確率分布は、$p(x;\\theta)$の形で表記していたが、今後は$p_\\theta(x)$とする。どちらも同じ意味を持つ確率分布である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa595c1-b3fc-46a9-8352-cf16db9a427e",
   "metadata": {},
   "source": [
    "### 5.1.2 KLダイバージェンスの定義式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65810342-1b0b-4b36-9103-c786447fc4a1",
   "metadata": {},
   "source": [
    "ある二つの確率分布を測る尺度に **KLダイバージェンス(Kullback-Leibler divergence)** がある。\n",
    "\n",
    "二つの確率分布$p_\\theta(x),q_{\\theta}(x)$がある時、KLダイバージェンスは\n",
    "\n",
    "$$D_{KL}(p||q) = \\int p(x)\\log\\frac{p(x)}{q(x)}dx$$\n",
    "\n",
    "の式で表される。上式は連続型の確率変数の場合のKLダイバージェンスである。離散型の場合は、\n",
    "\n",
    "$$D_{KL}(p||q) = \\sum_xp(x)\\log\\frac{p(x)}{q(x)}$$\n",
    "\n",
    "と表記される。KLダイバージェンスには次の特徴がある。\n",
    "\n",
    "* 二つの確率分布が異なるほど大きな値を示す。\n",
    "* ０以上の値を取り、二つの確率分布が同じ時のみ０になる\n",
    "* 非対称な尺度であるため、$D_{KL}(p||q),D_{KL}(q||q)$異なる値になる。\n",
    "\n",
    "KLダイバージェンスは、二つの確率分布がどれくらい異なるかを表す尺度として利用される\n",
    "\n",
    "コインを例に実際にKLダイバージェンスを計算してみる。\n",
    "\n",
    "あるAコインの表が出る確率が70%、裏が出る確率が３０％とする。ある人が、コインの表が出る確率が５０％、裏が出る確率が50%であると推定する。\n",
    "\n",
    "コインAの確率分布を$p$推定した確率分布を$q$とするとKLダイバージェンスは次のように計算できる。\n",
    "\n",
    "$$D_{KL}(p||q) = 0.7\\log\\frac{0.7}{0.5}+0.3\\log\\frac{0.3}{0.5} = 0.021$$\n",
    "\n",
    "となる。次に、別の人が、表が出る確率が２０％、裏が出る確率が80%と推定したとする。KLダイバージェンスは\n",
    "\n",
    "$$D_{KL}(p||q) = 0.7\\log \\frac{0.7}{0.2}+0.3\\log\\frac{0.3}{0.8} = 0.58$$\n",
    "\n",
    "となる。はじめに推定した確率よりも大きくなっていることがわかる。最後に別の人が表が出る確率70%、裏が出る確率30%と推定したとするとKLダイバージェンスは\n",
    "\n",
    "$$D_{KL}(p||q) = 0.7\\log \\frac{0.7}{0.7}+0.3\\log\\frac{0.3}{0.3} = 0$$\n",
    "\n",
    "となり、一致することがわかる。他の値についても計算するため、簡単なプログラムを作って実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3a17fbb-791c-40c0-be73-c65ce4cf3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def KLdiv(p,q):\n",
    "    K = len(p)\n",
    "    D = 0\n",
    "    for k in range(K):\n",
    "        D += p[k] * np.log(p[k] / q[k])\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea0931-4689-4b56-bc5d-f12afa60bb67",
   "metadata": {},
   "source": [
    "KLダイバージェンスを計算する関数KLdiv()を作成する。引数には、真の確率pと推定している確率qをとしている。\n",
    "\n",
    "例題と同様に、コインの表と裏が出る確率を計算する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4018e5a-ec46-4eab-bcc9-466496f4914c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head  0.1 reverse  0.9\n",
      "                                                       KL-div  1.0325534177382862\n",
      "head  0.2 reverse  0.8\n",
      "                                                       KL-div  0.5826853020432394\n",
      "head  0.30000000000000004 reverse  0.7\n",
      "                                                       KL-div  0.33891914415488134\n",
      "head  0.4 reverse  0.6\n",
      "                                                       KL-div  0.18378689738681217\n",
      "head  0.5 reverse  0.5\n",
      "                                                       KL-div  0.08228287850505178\n",
      "head  0.6000000000000001 reverse  0.3999999999999999\n",
      "                                                       KL-div  0.021600854143546483\n",
      "head  0.7000000000000001 reverse  0.29999999999999993\n",
      "                                                       KL-div  -1.1102230246251575e-17\n",
      "head  0.8 reverse  0.19999999999999996\n",
      "                                                       KL-div  0.028167557595283457\n",
      "head  0.9 reverse  0.09999999999999998\n",
      "                                                       KL-div  0.15366358680379857\n"
     ]
    }
   ],
   "source": [
    "p = [0.7,0.3]\n",
    "\n",
    "Q = [[0.1*i , 1-0.1*i] for i in range(1,10)]\n",
    "\n",
    "for q in Q:\n",
    "    print(\"head \",q[0],\"reverse \",q[1])\n",
    "    print(\"                                                       KL-div \", KLdiv(p,q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd626a7-f5fb-4473-9618-6e4deabb04d2",
   "metadata": {},
   "source": [
    "KLダイバージェンスの値を見ると、表が出る確率が０.1、裏が出る確率が0.9の場合に最も大きくなっていることがわかる。また、事前に計算した通り、表70%裏30%ではKLダイバージェンスは非常に小さくなっていることがわかる。\n",
    "\n",
    "一方で、表60%裏40％の場合0.021であり、表80%裏20%の場合0.028である。同じ10％ずつの差だがKLダイバージェンスの値は異なっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d723a-0269-4290-af14-c49912015da0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.1.3 KLダイバージェンスと最尤推定の関係"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe144e-42c6-4074-9961-de2ae532a5ad",
   "metadata": {},
   "source": [
    "KLダイバージェンスと最尤推定の関係について話す。\n",
    "\n",
    "真の確率分布$p_*(x)$があり、サンプルデータ$\\{x^{(1)},x^{(2)},\\cdots,x^{(N)}\\}$を生成したとする。目的は、パラメータ$\\theta$で調整できる確率$p_{\\theta}(x)$を使用して、$p_*(x)$にできるだけ近い確率分布を作る。\n",
    "\n",
    "対数尤度を目的関数とする。\n",
    "\n",
    "$$\\log \\prod^N_{n=1}p_\\theta(x^{(n)})= \\sum^N_{n=1}\\log p_\\theta(x^{(n)})$$\n",
    "\n",
    "そして、この対数尤度を最大化するパラメータは次の式で表される。\n",
    "\n",
    "$$\\hat{\\theta}=\\arg\\max_\\theta\\sum^N_{n=1}\\log p_\\theta (x^{(n)})$$\n",
    "\n",
    "$\\arg\\max_\\theta$は最大値を与える引数$\\theta$を意味する。つまり、対数尤度を最大化する$\\theta$を計算する。この式は、KLダイバージェンスを用いて導出することができる。それを証明する。\n",
    "\n",
    "KLダイバージェンスは\n",
    "\n",
    "$$D_{KL}(p_*||p_\\theta) = \\int p_*(x)\\log\\frac{p_*(x)}{p_\\theta(x)}dx$$\n",
    "\n",
    "の式で表される。この式を計算するためには、すべての$x$について積分をする必要がある。しかし、$p_*(x)$の具体的な数式が不明であるため、計算ができない。そこで、**モンテカルロ法** を用いて近似する。\n",
    "\n",
    "モンテカルロ法を用いて、期待値を求める手法を説明する。\n",
    "\n",
    "$$\\mathbb{E}_{p_*(x)}[f(x)]=\\int p_*(x)f(x)dx$$\n",
    "\n",
    "は連続な確率変数$x$を持つ確率密度$p_*(x)$と、任意の関数$f(x)$である。モンテカルロ法を用いると上式は次のように近似できる。\n",
    "\n",
    "1. 確率分布$p_*(x)$に基づいてサンプル$\\{x^{(1)},x^{(2)},\\cdots,x^{(N)}\\}$を生成する。\n",
    "2. 各データ$x^{(i)}$における$f(x^{(i)})を求め、その平均を計算する。\n",
    "\n",
    "この手順により、積分を近似して表すことができる。\n",
    "\n",
    "$$\\mathbb{E}_{p_*(x)} = \\int p_*(x)f(x)dx \\approx \\frac{1}{N}\\sum^N_{n=1}f(x^{(n)})\\\\ (x^{(n)}\\sim p_*(x))$$\n",
    "\n",
    "記号$\\approx$は近似的に等しいことを意味し、$x^{(n)}\\sim p_*(x)$は$x^{(n)}$が確率分布$p_*(x)$に従うことを意味する。モンテカルロ法によって、関数$f(x)$の期待値を計算することができる。実際にモンテカルロ法を用いて期待値を求めてみる。\n",
    "\n",
    "確率$p(x)$を一様関数とし、定積分と同じ結果を得ることができる。関数$x^2$を区間$[0:1]$で定積分すると$\\frac{1}{3}$となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14f6bac9-976c-4c7c-9b8f-34b4f17f4a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32994007835910655\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "K=10000\n",
    "\n",
    "x = np.random.uniform(0, 1, K)\n",
    "\n",
    "exp_x = sum(x*x) / K\n",
    "\n",
    "print(exp_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08649f-6d7c-4d47-8f36-e784bcd965b4",
   "metadata": {},
   "source": [
    "実際に計算すると、$\\frac{1}{3}$に近くなっていることがわかる。\n",
    "\n",
    "モンテカルロ法は、ランダムに生成されたサンプルを用いて、問題をシミュレートし、それらのサンプルから求めた結果の平均を取ることで、計算結果の解を近似できることが実感できる。\n",
    "\n",
    "期待値における関数$f(x)$を$\\log\\frac{p_*(x)}{q_\\theta(x)}$としてモンテカルロ法を適用する。\n",
    "\n",
    "$$D_{KL}(p_*(x) || p_\\theta) = \\int p_*(x)\\log\\frac{p_*(x)}{p_\\theta(x)}dx \\\\\n",
    "\\approx \\frac{1}{N}\\sum^N_{n=1}\\log\\frac{p_*(x^{(n)}}{p_\\theta(x^{(n)}}(x^{(n)}\\sim p_*(x))\\\\\n",
    "=\\frac{1}{N} \\sum^N_{n=1} \\left( \\log p_*(x^{(n)})-\\log p_\\theta (x^{(n)})\\right)\n",
    "$$\n",
    "\n",
    "その結果、KLダイバージェンスは上のように変形される。目的は、$D_{KL}(p_* || p_\\theta)$を最小にする$\\theta$を求めることである。従って、$\\theta$を含まない項を無視して\n",
    "\n",
    "$$\\arg\\min_\\theta D_{KL} \\approx \\arg\\min_\\theta\\left(-\\frac{1}{N}\\sum^N_{n=1}\\log p_\\theta(x_n)\\right) \\\\\n",
    " = \\arg\\min_\\theta \\left( - \\sum ^N_{n=1}\\log p_\\theta(x_n)\\right)\\\\\n",
    " = \\arg\\max_\\theta \\sum^N_{n=1}\\log p_\\theta(x_n)$$\n",
    " \n",
    "途中で、目的関数を$N$倍しているが、最小値をとる$\\theta$は変わらない。目的関数の符号を反転させると、最小の$\\min$から、最大の$\\max$に変わる。以上より\n",
    "\n",
    "$$\\arg\\min_\\theta D_{KL}(p_*||p_\\theta)\\approx \\arg\\max_\\theta\\sum^N_{n=1}\\log p_\\theta(x_n)$$\n",
    "\n",
    "となる。左辺は、KLダイバージェンスが最小となる$\\theta$、右辺は対数尤度が最大となる$\\theta$を意味している。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8713dd-88a5-4b49-b5ff-4697330dcf2a",
   "metadata": {},
   "source": [
    "## 5.2 EMアルゴリズムの導出①"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e034d-55fe-4f5d-b8ae-67b979e8585b",
   "metadata": {},
   "source": [
    "GMMは潜在変数を持つ確率分布のモデルである。潜在変数を持つモデルは他にもVAEやHMMがある。HMM隠れマルコフモデルの略である。\n",
    "\n",
    "EMアルゴリズムは、GMMだけではなく、潜在変数を持つモデルに対して適用することができる。はじめに、潜在変数を持つモデルに適応しその後にGMMに適応する。\n",
    "\n",
    "EMアルゴリズムはExpectation-Maximizationの略で、ExpectationステップとMaximizationステップを繰り返し、パラメータを更新する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26ea22-d480-4c5e-86b3-b8efbdd2033c",
   "metadata": {},
   "source": [
    "### 5.2.1 潜在変数を持つモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c4ee7-5531-411c-a417-cc9b84300a3d",
   "metadata": {},
   "source": [
    "観測できる確率変数を$x$潜在変数を$z$、パラメータ$\\theta$で表す。対数尤度は、確率の周辺化により、次の式で表される。\n",
    "\n",
    "$$\\log p_\\theta(x)=\\log\\sum_zp_\\theta(x,z)$$\n",
    "\n",
    "真の確率分布$p_*$からサンプル$\\mathcal{D}=\\{x^{(1)},x^{(2)},\\cdots,x^{(n)}\\}$が得られたとする。この時の対数尤度は\n",
    "\n",
    "$$\\log p_\\theta(\\mathcal{D}) = \\log\\left(p_\\theta(x^{(1)}p_\\theta(x^{(2)})\\cdots p_\\theta(x^{(n)}\\right)\\\\\n",
    " = \\sum^N_{n=1}\\log p_\\theta(x^{(n)}) \\\\\n",
    " = \\sum^N_{n=1}\\log\\sum_{z(n)}p_\\theta(x^{(n)},z^{(z)})$$\n",
    "この対数尤度を最大化したいが、log-sumの形だったが、EMアルゴリズムはこの問題をsum-logの形に変換し解く。\n",
    "\n",
    "まずは、乗法定理を使用し式を変形させる。\n",
    "\n",
    "$$\\log p_\\theta(x) = \\log\\frac{p_\\theta(x,z)}{p_\\theta(z|x)}$$\n",
    "\n",
    "一見、対数を加減にすることで解決しているように見えるが、条件付き確率$p_\\theta(z|x)$が難点である。なぜなら、ベイズ定理より\n",
    "\n",
    "$$p_\\theta(z|x)=\\frac{p_\\theta(x,z)}{\\sum_zp_\\theta(x,z)}$$\n",
    "\n",
    "と表される。分母に$\\sum$があり、log-sumの形から逃れることができない。\n",
    "\n",
    "\n",
    "\n",
    "ここでは、離散型を想定しているが、連続型では、$\\sum$を$\\int$にかえることで同様の結果が得られる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23367c-5327-45c9-ac16-2d2aff8cdda0",
   "metadata": {},
   "source": [
    "### 5.2.2 任意の確率分布$q(z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af63394-a7ac-4e11-9f0c-94fa8e119a75",
   "metadata": {},
   "source": [
    "厄介者である$p(z|x)$に対処するため、任意の確率分布$q(z)$を使用する。$q(z)$は、$p_\\theta(z|x)$の近似分布として用いる。\n",
    "\n",
    "対数尤度を$q(z)$を使用して\n",
    "\n",
    "$$\\log p_\\theta(x) = \\log\\frac{p_\\theta(x,z)}{p(z|x)} = \\log\\frac{p_\\theta(x,z)}{p(z|x)}\\frac{q(z)}{q(z)}=\\log\\frac{p_\\theta(x,z)}{q(z)}+\\log\\frac{q(z)}{p(z|x)}$$\n",
    "\n",
    "と表すことができる。この確率密度$q(z)$が潜在変数に対応しているように見える。\n",
    "\n",
    "第一項は$p(z|x)$から$q(z)$へ変更することができた。一方で、第二項には$p(z|x)$が存在する。よって第二項をKLダイバージェンスの形式に変形する。\n",
    "\n",
    "$$\\log p_\\theta(x) = \\log p_\\theta(x) \\sum_zq(z) \\\\\n",
    " = \\sum q(z)\\left(\\log\\frac{p_\\theta(x,z)}{q(z)}+\\log\\frac{q(z)}{p(z|x)}\\right)\\\\\n",
    " = \\sum q(z) \\log\\frac{p_\\theta(x,z)}{q(z)}+\\sum_z \\log\\frac{q(z)}{p(z|x)}\\\\\n",
    " = \\sum q(z) \\log\\frac{p_\\theta(x,z)}{q(z)}+D_{KL}(q(z)||p_\\theta(z|x))$$\n",
    "\n",
    "第二項をKLダイバージェンスとして表すことができた。これが、EMアルゴリズムを導くための式となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b3f67-2eea-4100-b1cb-38dd8c145b3b",
   "metadata": {},
   "source": [
    "## 5.3EMアルゴリズムの導出②"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26cb0f-8612-4af8-b2e2-e6e15b83320f",
   "metadata": {},
   "source": [
    "①で得られた対数尤度は\n",
    "\n",
    "$$ \\log p_\\theta(x)=\\sum_z q(z)\\log \\frac{p_\\theta(x,z)}{q(z)}+D_{KL}(q(z)||p_\\theta(z|x)$$\n",
    "\n",
    "である。この式似ついて考察を続ける。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33327b5-7785-4ae7-8629-71046efd4402",
   "metadata": {},
   "source": [
    "### 5.3.1ELBO(エビデンスの下界)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39915d8d-d70c-4b29-8602-e223d1544344",
   "metadata": {},
   "source": [
    "KLダイバージェンスの計算結果は、常に０以上になる。そのため、\n",
    "\n",
    "$$ \\log p_\\theta(x)=\\sum_z q(z)\\log \\frac{p_\\theta(x,z)}{q(z)}+D_{KL}(q(z)||p_\\theta(z|x) \\geq \\sum_z q(z)\\log \\frac{p_\\theta(x,z)}{q(z)}$$\n",
    "\n",
    "が成立する。第一項の$\\sum_z \\log \\frac{p_\\theta(x,z)}{q(z)}$は、対数尤度以下の値であり、ELBO(Evidence Lower BOund)と呼ばれエビデンスの下界と訳される。\n",
    "\n",
    "この場合のエビデンスは、対数尤度が大きくなることで$q$,$\\theta$が正しい方向を示している根拠であることを示す。この第一式は、ELBOと呼ばれ\n",
    "\n",
    "$$\\rm{ELBO}(x;q,\\theta)=\\sum_zq(z)\\log\\frac{p_\\theta(x,z)}{q(z)}$$\n",
    "\n",
    "の表記を用いる。$\\rm{ELBO}(x;q,\\theta)$には重要な特徴があり\n",
    "\n",
    "* 対数尤度$\\log p_\\theta(x)$は常に$\\rm{ELBO}(x;q,\\theta)$以上の値になる\n",
    "* $\\rm{ELBO}(x;q,\\theta)$はsum-logの形になっており、解析しやすい\n",
    "\n",
    "ELBOを大きくするようにパラメータを更新する。$\\log p_\\theta(x)$の代わりとして、ELBOを最適化の対象にすることを考える。\n",
    "\n",
    "つまり、対数尤度の第一項に注目し最適化する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ee532-f1ce-4f08-8c46-b5510abff52d",
   "metadata": {},
   "source": [
    "### 5.3.2EMアルゴリズムへ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93808bc8-e0f4-4dac-becf-1ba1057c3bb6",
   "metadata": {},
   "source": [
    "$\\rm{ELGO}(x;q,\\theta)$には$q(z),\\theta$の二つのパラメータがある。この二つのパラメータを最適化しELGOを最大化する。\n",
    "\n",
    "二つのパラメータを同時に最適化することは難しいため、一方を固定しもう片方のパラメータを最適化する。この作業を繰り返す。\n",
    "\n",
    "まずは、$\\theta=\\theta_{\\rm{old}}$として$\\theta$を固定し$q(z)$を最適化する。\n",
    "\n",
    "$q(z)$の分布によって、$\\rm{ELBO}(x;q,\\theta)$が$\\log p_\\theta(x)$にどれくらい近づくかが変化する。これは、KLダイバージェンスがゼロに近づくことで、対数尤度と$\\rm{ELBO}$が等しくなる。\n",
    "\n",
    "式\n",
    "\n",
    "$$\\log p_\\theta(x) = \\rm{ELBO}(x;q,\\theta)+D_{\\rm{KL}}(q(z)||p_\\theta(z|x))$$\n",
    "\n",
    "に注目すると、対数尤度では任意の確率分布$q(z)$に依らずELBO項とKL項の和が一定であることがわかる。\n",
    "\n",
    "KL項を小さくすることで、ELBO項は大きくなる。KLダイバージェンスは$q(z)$と$p_\\theta(z|x)$が等しい場合に０となる。その時の対数尤度$\\log p_\\theta(x)$は$\\rm{ELBO}(x;q,\\theta)$と等しくなる。\n",
    "\n",
    "よって、$q(z)$の更新式は$q(z)=p_{\\theta_{\\rm{old}}}(z|x)$と表すことができる。つまり、KLダイバージェンスが小さくなるように、確率分布を変化させる。\n",
    "\n",
    "$q(z)=p_{\\theta_{\\rm{old}}}(z|x)$による更新は、Eステップと呼ばれる。これはExpectation ValueのEからきている。これは、$q(z)=p_{\\theta_{\\rm{old}}}(z|x)$の時ELBOが\n",
    "\n",
    "$$\\rm{ELBO}(x;q=p_{\\theta_{\\rm{old}}}(z|x),\\theta) = \\sum_zp_{\\theta_{\\rm{old}}}(z|x)\\log\\frac{p_\\theta(x,z)}{p_{\\theta_{\\rm{old}}}(z|x)} = \\mathbb{E}_{{\\theta_{\\rm{old}}}(z|x)}\\left[ \\log\\frac{p_\\theta(x,z)}{p_{\\theta_{\\rm{old}}}(z|x)} \\right]$$\n",
    "\n",
    "期待値として表されることに起因する。\n",
    "\n",
    "次に$\\theta$の最適化を行う。これは、解析的に求めることができる。Mステップと呼ばれ、Maximizationの頭文字から来ている。\n",
    "\n",
    "Mステップを行うことで、ELBOの値は増加するが一方でEステップで一致した対数尤度とELBOは遠ざかる。\n",
    "\n",
    "EステップとMステップを交互に繰り返すことで、対数尤度が変化しなくなる。EMアルゴリズムによる更新のやめ時である。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e674e9dc-1b97-4dec-a5a0-28abbfd5e3b4",
   "metadata": {},
   "source": [
    "### 中まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e77a65-9b27-4ed5-a6c0-3b74ab9531dd",
   "metadata": {},
   "source": [
    "対数尤度は潜在変数$z$を生成する任意の確率分布$q(z)$を使用して\n",
    "\n",
    "$$\\log p_\\theta(x) = \\sum q(z) \\log\\frac{p_\\theta(x,z)}{q(z)}+D_{KL}(q(z)||p_\\theta(z|x))$$\n",
    "\n",
    "と表される。対数尤度の下限Expectation Lower BOundaryは第一項である。これは、KLダイバージェンスが０以上になるためである。\n",
    "\n",
    "$$\\rm{ELBO}(x;q,\\theta)=\\sum_zq(z)\\log\\frac{p_\\theta(x,z)}{q(z)}$$\n",
    "\n",
    "対数尤度を最大化するために、ELBOを最大化する。ELBOは$q(z),\\theta$の二つの変数を持つ関数であるため、$q(z), \\theta$をそれぞれ更新させる。\n",
    "\n",
    "$q(z)$を更新するステップをEステップ、$\\theta$を更新するステップをMステップと呼ぶ。呼称は、それぞれの更新に使用する式から期待値のExpectation,最大値のMaximizationの頭文字をとっている。\n",
    "\n",
    "Eステップでは、$\\theta={\\theta_{\\rm{old}}}$と固定し、$q(z)=p_{\\theta_\\rm{old}}(z|x)$の更新式を用いて更新する。つまり、$q(z)$を$p_{\\theta_\\rm{old}}(z|x)$に近づける。\n",
    "更新し、ELBOを対数尤度に近づける。\n",
    "\n",
    "Mステップでは、ELBOが最大になる$\\theta$を計算する。\n",
    "Eステップで計算したELBOと対数尤度は遠ざかる。\n",
    "\n",
    "このEステップとMステップを交互に繰り返すことで対数尤度を徐々に大きくする。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e7d32-5937-492e-90bd-2e1888296923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
